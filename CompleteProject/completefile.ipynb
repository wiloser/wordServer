{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.777431Z",
     "start_time": "2024-10-18T05:24:16.774485Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.807770Z",
     "start_time": "2024-10-18T05:24:16.795827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zhang Suen 细化算法，进行骨架提取\n",
    "def Zhang_Suen_thinning(img):\n",
    "    # Get image shape\n",
    "    H, W = img.shape\n",
    "\n",
    "    # Prepare output image\n",
    "    out = np.zeros((H, W), dtype=np.int32)\n",
    "    out[img[..., 0] > 0] = 1\n",
    "\n",
    "    # Inverse image (white background, black character)\n",
    "    out = 1 - out\n",
    "\n",
    "    while True:\n",
    "        s1 = []\n",
    "        s2 = []\n",
    "\n",
    "        # Step 1 (raster scan)\n",
    "        for y in range(1, H - 1):\n",
    "            for x in range(1, W - 1):\n",
    "\n",
    "                # Skip non-edge pixels\n",
    "                if out[y, x] > 0:\n",
    "                    continue\n",
    "\n",
    "                # Condition 2\n",
    "                f1 = 0\n",
    "                if (out[y - 1, x + 1] - out[y - 1, x]) == 1: f1 += 1\n",
    "                if (out[y, x + 1] - out[y - 1, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x + 1] - out[y, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x] - out[y + 1, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x - 1] - out[y + 1, x]) == 1: f1 += 1\n",
    "                if (out[y, x - 1] - out[y + 1, x - 1]) == 1: f1 += 1\n",
    "                if (out[y - 1, x - 1] - out[y, x - 1]) == 1: f1 += 1\n",
    "                if (out[y - 1, x] - out[y - 1, x - 1]) == 1: f1 += 1\n",
    "\n",
    "                if f1 != 1:\n",
    "                    continue\n",
    "\n",
    "                # Condition 3\n",
    "                f2 = np.sum(out[y - 1:y + 2, x - 1:x + 2])\n",
    "                if f2 < 2 or f2 > 6:\n",
    "                    continue\n",
    "\n",
    "                # Condition 4 and 5\n",
    "                if (out[y - 1, x] + out[y, x + 1] + out[y + 1, x]) < 1: continue\n",
    "                if (out[y, x + 1] + out[y + 1, x] + out[y, x - 1]) < 1: continue\n",
    "\n",
    "                s1.append([y, x])\n",
    "\n",
    "        for v in s1:\n",
    "            out[v[0], v[1]] = 1\n",
    "\n",
    "        # Step 2 (raster scan)\n",
    "        for y in range(1, H - 1):\n",
    "            for x in range(1, W - 1):\n",
    "\n",
    "                if out[y, x] > 0:\n",
    "                    continue\n",
    "\n",
    "                # Same conditions as step 1\n",
    "                f1 = 0\n",
    "                if (out[y - 1, x + 1] - out[y - 1, x]) == 1: f1 += 1\n",
    "                if (out[y, x + 1] - out[y - 1, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x + 1] - out[y, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x] - out[y + 1, x + 1]) == 1: f1 += 1\n",
    "                if (out[y + 1, x - 1] - out[y + 1, x]) == 1: f1 += 1\n",
    "                if (out[y, x - 1] - out[y + 1, x - 1]) == 1: f1 += 1\n",
    "                if (out[y - 1, x - 1] - out[y, x - 1]) == 1: f1 += 1\n",
    "                if (out[y - 1, x] - out[y - 1, x - 1]) == 1: f1 += 1\n",
    "\n",
    "                if f1 != 1:\n",
    "                    continue\n",
    "\n",
    "                f2 = np.sum(out[y - 1:y + 2, x - 1:x + 2])\n",
    "                if f2 < 2 or f2 > 6:\n",
    "                    continue\n",
    "\n",
    "                if (out[y - 1, x] + out[y, x + 1] + out[y, x - 1]) < 1: continue\n",
    "                if (out[y - 1, x] + out[y + 1, x] + out[y, x - 1]) < 1: continue\n",
    "\n",
    "                s2.append([y, x])\n",
    "\n",
    "        for v in s2:\n",
    "            out[v[0], v[1]] = 1\n",
    "\n",
    "        if len(s1) < 1 and len(s2) < 1:\n",
    "            break\n",
    "\n",
    "    out = apply_template_removal(out, H, W)\n",
    "\n",
    "    out = 1 - out\n",
    "    out = out.astype(np.uint8) * 255\n",
    "\n",
    "    return out"
   ],
   "id": "a5250454d38e7db2",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.824547Z",
     "start_time": "2024-10-18T05:24:16.816120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 空洞或噪声消除模板\n",
    "def apply_template_removal(out, H, W):\n",
    "    for y in range(1, H-1):\n",
    "        for x in range(1, W-1):\n",
    "            P = out[y-1:y+2, x-1:x+2].flatten()\n",
    "            if (P[1] * P[7] == 1 and sum([P[3], P[4], P[5], P[8]]) == 0) or \\\n",
    "               (P[5] * P[7] == 1 and sum([P[1], P[2], P[3], P[6]]) == 0) or \\\n",
    "               (P[1] * P[3] == 1 and sum([P[2], P[5], P[6], P[7]]) == 0) or \\\n",
    "               (P[3] * P[5] == 1 and sum([P[1], P[4], P[7], P[8]]) == 0) or \\\n",
    "               (sum([P[2], P[4], P[6], P[8]]) == 0 and sum([P[1], P[3], P[5], P[7]]) == 3):\n",
    "                out[y, x] = 1\n",
    "    return out\n",
    "\n",
    "def apply_template(image, template):\n",
    "    \"\"\"根据给定模板进行处理，消除噪声或孔洞\"\"\"\n",
    "    h, w = image.shape\n",
    "    processed_image = image.copy()\n",
    "    for i in range(1, h - 1):\n",
    "        for j in range(1, w - 1):\n",
    "            # 获取8邻域\n",
    "            neighborhood = image[i - 1:i + 2, j - 1:j + 2]\n",
    "            # 与模板匹配\n",
    "            if np.array_equal(neighborhood, template):\n",
    "                processed_image[i, j] = 0  # 将符合条件的前景点更改为背景点\n",
    "    return processed_image\n",
    "\n",
    "# 凹凸点和孤立点模板\n",
    "templates_bumps_isolated = [\n",
    "    np.array([[0, 0, 0], [0, 1, 0], [1, 1, 1]]),\n",
    "    np.array([[1, 0, 0], [1, 1, 0], [1, 0, 0]]),\n",
    "\n",
    "]\n",
    "# 孔洞消除模板\n",
    "templates_holes = [\n",
    "    np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]]),\n",
    "\n",
    "]\n",
    "\n",
    "# 应用模板处理图像\n",
    "def preprocess_image(image):\n",
    "    # 处理凹凸点和孤立点\n",
    "    for template in templates_bumps_isolated:\n",
    "        image = apply_template(image, template)\n",
    "\n",
    "    # 处理孔洞\n",
    "    for template in templates_holes:\n",
    "        image = apply_template(image, template)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_images(image1, image2):\n",
    "    \"\"\"\n",
    "    处理两个输入图像，分别处理凹凸点、孤立点和孔洞。\n",
    "    \"\"\"\n",
    "    # 分别处理 image1 和 image2\n",
    "    processed_image1 = preprocess_image(image1)\n",
    "    processed_image2 = preprocess_image(image2)\n",
    "\n",
    "    return processed_image1, processed_image2\n",
    "\n",
    "#可以输出细化后的骨架，先细化在进行归一化"
   ],
   "id": "82cea36313e5f8f6",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.839369Z",
     "start_time": "2024-10-18T05:24:16.832011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binarize_image(image, threshold=127):\n",
    "    \"\"\" 将灰度图像二值化 \"\"\"\n",
    "    _, binary_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "def calculate_center_of_mass_from_contour(image):\n",
    "    \"\"\" 通过轮廓提取计算图像的重心坐标 \"\"\"\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return image.shape[1] // 2, image.shape[0] // 2  # 返回图像中心\n",
    "    \n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    M = cv2.moments(max_contour)\n",
    "    \n",
    "    if M['m00'] == 0:\n",
    "        return image.shape[1] // 2, image.shape[0] // 2  # 返回图像中心\n",
    "\n",
    "    center_x = int(M['m10'] / M['m00'])\n",
    "    center_y = int(M['m01'] / M['m00'])\n",
    "    \n",
    "    return center_x, center_y\n",
    "\n",
    "def resize_and_center_images_to_equal_size(template, student, output_size=(400, 400)):\n",
    "    \"\"\" 调整模板和临摹图像，使它们的框大小一致并居中 \"\"\"\n",
    "    # Step 1: 将灰度图像转换为二值图像\n",
    "    binary_template = binarize_image(template)\n",
    "    binary_student = binarize_image(student)\n",
    "    \n",
    "    # Step 2: 计算模板和临摹图像的外接矩形 (Bounding Box)\n",
    "    x_T, y_T, w_T, h_T = cv2.boundingRect(binary_template)\n",
    "    x_C, y_C, w_C, h_C = cv2.boundingRect(binary_student)\n",
    "\n",
    "    # Step 3: 选择模板和临摹字中较大的宽高，确保两个图像的框大小相等\n",
    "    max_width = max(w_T, w_C)\n",
    "    max_height = max(h_T, h_C)\n",
    "\n",
    "    # Step 4: 调整大小，使两者的框大小一致\n",
    "    template_resized = cv2.resize(binary_template[y_T:y_T+h_T, x_T:x_T+w_T], (max_width, max_height))\n",
    "    student_resized = cv2.resize(binary_student[y_C:y_C+h_C, x_C:x_C+w_C], (max_width, max_height))\n",
    "    \n",
    "    # Step 5: 创建400x400的空白背景\n",
    "    blank_template = np.ones(output_size, dtype=np.uint8) * 255  # 模板字空白图\n",
    "    blank_student = np.ones(output_size, dtype=np.uint8) * 255   # 临摹字空白图\n",
    "    \n",
    "    # Step 6: 计算重心\n",
    "    template_center_x, template_center_y = calculate_center_of_mass_from_contour(template_resized)\n",
    "    student_center_x, student_center_y = calculate_center_of_mass_from_contour(student_resized)\n",
    "    \n",
    "    # Step 7: 将模板字和临摹字放置在400x400的空白图中，确保居中并且框大小一致\n",
    "    start_x_T = output_size[1] // 2 - template_resized.shape[1] // 2\n",
    "    start_y_T = output_size[0] // 2 - template_resized.shape[0] // 2\n",
    "    blank_template[start_y_T:start_y_T+template_resized.shape[0], start_x_T:start_x_T+template_resized.shape[1]] = template_resized\n",
    "    \n",
    "    start_x_C = output_size[1] // 2 - student_resized.shape[1] // 2\n",
    "    start_y_C = output_size[0] // 2 - student_resized.shape[0] // 2\n",
    "    blank_student[start_y_C:start_y_C+student_resized.shape[0], start_x_C:start_x_C+student_resized.shape[1]] = student_resized\n",
    "    \n",
    "    return blank_template, blank_student\n",
    "\n",
    "#可以输出归一化后的图片\n"
   ],
   "id": "2d29f2a53d9ff04a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.850742Z",
     "start_time": "2024-10-18T05:24:16.846041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#骨架相似度评价，用的是像素计算。（也可用坐标计算）\n",
    "# 计算两个点之间的欧几里得距离\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
    "\n",
    "# 计算一个点到一组骨架点的最小距离\n",
    "def point_to_skeleton_distance(point, skeleton_points):\n",
    "    return min(euclidean_distance(point, sk_point) for sk_point in skeleton_points)\n",
    "\n",
    "# 计算两个骨架图像之间的总距离\n",
    "def calculate_total_distance(skeleton1, skeleton2):\n",
    "    skeleton1_points = np.argwhere(skeleton1 == 255)  # 骨架为白色\n",
    "    skeleton2_points = np.argwhere(skeleton2 == 255)  # 骨架为白色\n",
    "    total_distance = sum(point_to_skeleton_distance(point, skeleton2_points) for point in skeleton1_points)\n",
    "    \n",
    "    print(\"骨架相似度计算\",total_distance)\n",
    "    \n",
    "    return total_distance"
   ],
   "id": "a28d69ad245a1733",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.861795Z",
     "start_time": "2024-10-18T05:24:16.857387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------笔画提取--------------------------------\n",
    "def extract_grid_image(imageData, position):\n",
    "    height, width = imageData.shape[:2]\n",
    "    grid_height = height // 3\n",
    "    grid_width = width // 3\n",
    "    x, y = position\n",
    "    start_x = x * grid_width\n",
    "    start_y = y * grid_height\n",
    "    end_x = start_x + grid_width\n",
    "    end_y = start_y + grid_height\n",
    "    end_x = min(end_x, width)\n",
    "    end_y = min(end_y, height)\n",
    "    grid_image = imageData[start_y:end_y, start_x:end_x]\n",
    "    return grid_image\n",
    "\n",
    "# 定义函数计算图像的Hu矩\n",
    "def calculate_hu_moments(image):\n",
    "    if cv2.countNonZero(image) == 0:\n",
    "        return np.zeros(7)  # 返回零矩阵避免 nan\n",
    "    moments = cv2.moments(image)\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    return hu_moments\n"
   ],
   "id": "c8e6e6d3b59c9011",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T05:24:16.873826Z",
     "start_time": "2024-10-18T05:24:16.868438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 计算笔画相似度\n",
    "def StrokeExtractionAndSimilarityEvaluation(imageData, reference_image):\n",
    "    handwriting_hu_moments = calculate_hu_moments(imageData)\n",
    "    template_hu_moments = calculate_hu_moments(reference_image)\n",
    "\n",
    "    grid_positions = [(0, 0), (0, 1), (0, 2),\n",
    "                      (1, 0), (1, 1), (1, 2),\n",
    "                      (2, 0), (2, 1), (2, 2)]\n",
    "\n",
    "    grid_weights = [0.1, 0.1, 0.1,\n",
    "                    0.1, 0.5, 0.1,\n",
    "                    0.1, 0.1, 0.1]\n",
    "\n",
    "    handwriting_hu_moments_list = []\n",
    "    template_hu_moments_list = []\n",
    "\n",
    "    for position in grid_positions:\n",
    "        handwriting_grid_image = extract_grid_image(imageData, position)\n",
    "        template_grid_image = extract_grid_image(reference_image, position)\n",
    "\n",
    "        handwriting_hu_moments = calculate_hu_moments(handwriting_grid_image)\n",
    "        template_hu_moments = calculate_hu_moments(template_grid_image)\n",
    "\n",
    "        handwriting_hu_moments_list.append(handwriting_hu_moments)\n",
    "        template_hu_moments_list.append(template_hu_moments)\n",
    "\n",
    "    correlation_coefficients = []\n",
    "    for handwriting_hu_moments, template_hu_moments in zip(handwriting_hu_moments_list, template_hu_moments_list):\n",
    "        correlation_coefficient = np.corrcoef(handwriting_hu_moments, template_hu_moments)[0, 1]\n",
    "        if np.isnan(correlation_coefficient):\n",
    "            correlation_coefficient = 0  # 避免 nan\n",
    "        correlation_coefficients.append(correlation_coefficient)\n",
    "\n",
    "    # 确保 correlation_coefficients 和 grid_weights 都是数值类型列表\n",
    "    correlation_coefficients = np.array(correlation_coefficients, dtype=float)\n",
    "    grid_weights = np.array(grid_weights, dtype=float)\n",
    "\n",
    "    # 计算加权和\n",
    "    weighted_sum = np.dot(correlation_coefficients, grid_weights)\n",
    "\n",
    "    # 确保 weighted_sum 是浮点数并乘以常量\n",
    "    weighted_sum = float(weighted_sum) * 76.924\n",
    "    weighted_sum = round(weighted_sum, 2)\n",
    "\n",
    "    # 根据相似度值返回相应的描述\n",
    "    if weighted_sum < 20:\n",
    "        description = '笔画极其不相似，与模板差异极大'\n",
    "    elif weighted_sum < 40:\n",
    "        description = '笔画很不相似，需要大幅度改进'\n",
    "    elif weighted_sum < 60:\n",
    "        description = '笔画不太相似，部分偏离模板'\n",
    "    elif weighted_sum < 80:\n",
    "        description = '笔画位置基本相似，但仍有改进空间'\n",
    "    else:\n",
    "        description = '笔画位置非常相似，与模板高度一致'\n",
    "\n",
    "    print('笔画相似度:', weighted_sum,description)\n",
    "    return weighted_sum, description"
   ],
   "id": "ff455cf7b2172408",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:22:33.560185Z",
     "start_time": "2024-10-18T07:20:13.938203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    template_path = r\"E:\\python files\\PycharmProjects\\CompleteProject\\4.png\"\n",
    "    handwriting_path = r\"E:\\python files\\PycharmProjects\\CompleteProject\\18.png\"\n",
    "    \n",
    "    # 读取灰度图像\n",
    "    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    handwriting = cv2.imread(handwriting_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # 反色处理\n",
    "    # img1 = cv2.bitwise_not(template)\n",
    "    # img2 = cv2.bitwise_not(handwriting)\n",
    "\n",
    "    # if img1 is None or img2 is None:\n",
    "    #     print(\"Error loading images.\")\n",
    "    #     return\n",
    "    #    # 骨架提取\n",
    "    \n",
    "    out1 = Zhang_Suen_thinning(template)\n",
    "    out2 = Zhang_Suen_thinning(handwriting)\n",
    "    aligned_template, aligned_handwriting = preprocess_images(out1, out2)\n",
    " \n",
    "    # 调整临摹字大小并将它们都显示在400x400的空白图中\n",
    "    aligned_template1, aligned_handwriting1 = resize_and_center_images_to_equal_size( aligned_template,  aligned_handwriting)\n",
    "\n",
    "    # 计算骨架相似度\n",
    "    skeleton_similarity_score = calculate_total_distance(aligned_template1, aligned_handwriting1)\n",
    "    \n",
    "    # 计算布局相似度，hu矩九宫格\n",
    "    weighted_score, description = StrokeExtractionAndSimilarityEvaluation(aligned_template1, aligned_handwriting1)\n",
    "\n",
    "    # 计算总分\n",
    "    full_score = skeleton_similarity_score * 0.5 + weighted_score * 0.5\n",
    "    print(\"总分：\", full_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "1c35021b8bbe8e57",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[57], line 35\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m总分：\u001B[39m\u001B[38;5;124m\"\u001B[39m, full_score)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 35\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[57], line 25\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     22\u001B[0m aligned_template1, aligned_handwriting1 \u001B[38;5;241m=\u001B[39m resize_and_center_images_to_equal_size( aligned_template,  aligned_handwriting)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 计算骨架相似度\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m skeleton_similarity_score \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_total_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43maligned_template1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maligned_handwriting1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# 计算布局相似度，hu矩九宫格\u001B[39;00m\n\u001B[0;32m     28\u001B[0m weighted_score, description \u001B[38;5;241m=\u001B[39m StrokeExtractionAndSimilarityEvaluation(aligned_template1, aligned_handwriting1)\n",
      "Cell \u001B[1;32mIn[53], line 14\u001B[0m, in \u001B[0;36mcalculate_total_distance\u001B[1;34m(skeleton1, skeleton2)\u001B[0m\n\u001B[0;32m     12\u001B[0m skeleton1_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margwhere(skeleton1 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m255\u001B[39m)  \u001B[38;5;66;03m# 骨架为白色\u001B[39;00m\n\u001B[0;32m     13\u001B[0m skeleton2_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margwhere(skeleton2 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m255\u001B[39m)  \u001B[38;5;66;03m# 骨架为白色\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m total_distance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpoint_to_skeleton_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskeleton2_points\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpoint\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mskeleton1_points\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m骨架相似度计算\u001B[39m\u001B[38;5;124m\"\u001B[39m,total_distance)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_distance\n",
      "Cell \u001B[1;32mIn[53], line 14\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     12\u001B[0m skeleton1_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margwhere(skeleton1 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m255\u001B[39m)  \u001B[38;5;66;03m# 骨架为白色\u001B[39;00m\n\u001B[0;32m     13\u001B[0m skeleton2_points \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margwhere(skeleton2 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m255\u001B[39m)  \u001B[38;5;66;03m# 骨架为白色\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m total_distance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[43mpoint_to_skeleton_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskeleton2_points\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m point \u001B[38;5;129;01min\u001B[39;00m skeleton1_points)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m骨架相似度计算\u001B[39m\u001B[38;5;124m\"\u001B[39m,total_distance)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_distance\n",
      "Cell \u001B[1;32mIn[53], line 8\u001B[0m, in \u001B[0;36mpoint_to_skeleton_distance\u001B[1;34m(point, skeleton_points)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpoint_to_skeleton_distance\u001B[39m(point, skeleton_points):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43meuclidean_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msk_point\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msk_point\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mskeleton_points\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[53], line 8\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpoint_to_skeleton_distance\u001B[39m(point, skeleton_points):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(euclidean_distance(point, sk_point) \u001B[38;5;28;01mfor\u001B[39;00m sk_point \u001B[38;5;129;01min\u001B[39;00m skeleton_points)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T07:19:31.825632200Z",
     "start_time": "2024-10-18T05:05:47.049995Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7acef05646119270",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
